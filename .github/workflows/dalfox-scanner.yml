name: "Dalfox XSS Scanner (Parallel)"

on:
  workflow_dispatch:
    inputs:
      target_name:
        description: 'Name of target folder in storage repo'
        required: true
      storage_repo:
        description: 'SSH URL of scan-results-storage repo'
        required: true
      custom_cookie:
        description: 'Optional: Custom Cookie header'
        required: false
        default: ''
      custom_header:
        description: 'Optional: Custom extra header'
        required: false
        default: ''

jobs:
  fetch-results:
    runs-on: ubuntu-latest
    outputs:
      urls_exist: ${{ steps.check_files.outputs.urls_exist }}
    steps:
      - name: Setup SSH and Git
        env:
          DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
        run: |
          mkdir -p ~/.ssh/
          echo "${DEPLOY_KEY}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan github.com >> ~/.ssh/known_hosts
      - name: Clone storage repo and copy files
        run: |
          git clone ${{ github.event.inputs.storage_repo }} storage
          mkdir -p combined-results
          cp storage/${{ github.event.inputs.target_name }}/discovery/live-urls.txt combined-results/ 2>/dev/null || echo "No live-urls.txt file found"
      - name: Check if files exist
        id: check_files
        run: |
          if [[ -s "combined-results/live-urls.txt" ]]; then
            echo "urls_exist=true" >> $GITHUB_OUTPUT
          else
            echo "urls_exist=false" >> $GITHUB_OUTPUT
          fi
      - name: Upload combined results artifact
        uses: actions/upload-artifact@v4
        with:
          name: dalfox-combined-results-artifact
          path: combined-results/

  dalfox-scan:
    needs: fetch-results
    if: "needs.fetch-results.outputs.urls_exist == 'true'"
    runs-on: ubuntu-latest
    strategy:
      matrix:
        chunk: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
    steps:
      - name: Checkout main branch
        uses: actions/checkout@v3
      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: dalfox-combined-results-artifact
          path: combined-results/
      - name: Setup Go
        uses: actions/setup-go@v3
        with:
          go-version: '1.23'
      - name: Install Dalfox
        run: go install github.com/hahwul/dalfox/v2@latest
      - name: Generate URL chunk file
        run: |
          if [ -s combined-results/live-urls.txt ]; then
            TOTAL_LINES=$(wc -l < combined-results/live-urls.txt)
            LINES_PER_CHUNK=$(( (TOTAL_LINES + 20 - 1) / 20 ))
            START_LINE=$((((${{ matrix.chunk }} - 1) * LINES_PER_CHUNK) + 1))
            END_LINE=$((${{ matrix.chunk }} * LINES_PER_CHUNK))
            sed -n "${START_LINE},${END_LINE}p" combined-results/live-urls.txt > dalfox-chunk-${{ matrix.chunk }}.txt
          else
            touch dalfox-chunk-${{ matrix.chunk }}.txt
          fi
      - name: Run Dalfox Scan on Chunk
        run: |
          set -e
          INPUT_FILE="dalfox-chunk-${{ matrix.chunk }}.txt"
          OUTPUT_FILE="dalfox-output-${{ matrix.chunk }}.txt"
          PAYLOAD_FILE="dalfox_payload.txt" # This file should exist in the repo
          BLIND_XSS_URL="https://1.bigdav.ir/dalfox-${{ github.event.inputs.target_name }}"

          if [ ! -s "$INPUT_FILE" ]; then
            echo "URL chunk file is empty, skipping Dalfox scan for this chunk."
            touch "$OUTPUT_FILE"
            exit 0
          fi

          # Build header arguments
          HEADER_ARGS=()
          if [[ -n "${{ github.event.inputs.custom_cookie }}" ]]; then
            HEADER_ARGS+=(-H "Cookie: ${{ github.event.inputs.custom_cookie }}")
          fi
          if [[ -n "${{ github.event.inputs.custom_header }}" ]]; then
            HEADER_ARGS+=(-H "${{ github.event.inputs.custom_header }}")
          fi

          $HOME/go/bin/dalfox file "$INPUT_FILE" \
            --custom-payload "$PAYLOAD_FILE" \
            -b "$BLIND_XSS_URL" \
            --silence \
            --skip-headless \
            --fast-scan \
            --skip-mining-all \
            -o "$OUTPUT_FILE" \
            "${HEADER_ARGS[@]}"
      - name: Upload Dalfox results artifact
        uses: actions/upload-artifact@v4
        with:
          name: dalfox-results-chunk-${{ matrix.chunk }}
          path: dalfox-output-${{ matrix.chunk }}.txt

  push-to-storage:
    needs: [dalfox-scan]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Setup SSH and Git
        env:
          DEPLOY_KEY: ${{ secrets.DEPLOY_KEY }}
        run: |
          mkdir -p ~/.ssh/
          echo "${DEPLOY_KEY}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan github.com >> ~/.ssh/known_hosts
          git config --global user.email "actions@github.com"
          git config --global user.name "GitHub Actions"
      - name: Download all scan results
        uses: actions/download-artifact@v4
        with:
          path: all-results
      - name: Push results to storage repo
        run: |
          git clone ${{ github.event.inputs.storage_repo }} storage
          mkdir -p storage/${{ github.event.inputs.target_name }}/xss

          DALFOX_FILE="storage/${{ github.event.inputs.target_name }}/xss/dalfox.txt"

          # Consolidate all dalfox output into a single file
          find all-results -type f -name "dalfox-output-*.txt" -exec cat {} + > "$DALFOX_FILE"

          cd storage
          git add .
          if ! git diff --staged --quiet; then
            git commit -m "Add parallel Dalfox scan results for ${{ github.event.inputs.target_name }}"
            git push
          else
            echo "No changes to commit"
          fi
